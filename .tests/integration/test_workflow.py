
import re
import subprocess as sp
from pathlib import Path
from typing import Any, Dict, Sequence

import pytest

import helpers as test_helpers


def test_invalid_configuration(run_dir: Path, config_template: Dict[str, Any], destination_local_path: Path):
    # The destination_local_path fixture is not accessed within the test but we need to use it
    # so that the local directory is cleaned after the execution of the test.
    # This assert is here merely to silence the warning about the argument not be accessed
    # generated by pyright and other linters.
    assert destination_local_path is not None

    cfg = config_template
    del cfg['recipient_key']
    # running the workflow should raise an error because of a failed schema validation
    with pytest.raises(sp.CalledProcessError):
        test_helpers.run_workflow(cfg, run_dir)
    

def _read_index(local_index: Path) -> Sequence[Sequence[str]]:
    assert local_index.exists()
    with open(local_index) as f:
        index = [line.rstrip('\n').split('\t') for line in f]

    return index


def _validate_received_file(file_path: Path) -> None:
    assert file_path.is_file()
    # we wrote the file name in the file, so we can assert that the contents 
    # are as expected
    with open(file_path) as f:
        assert f.read().rstrip('\n') == file_path.name

def _validate_index_row(row: Sequence[str]) -> None:
    # Random filename: it's a uuid with a .c4gh extension, as in
    #  '400a3b87-8f2b-477e-9984-91276150ebbd.c4gh'
    assert re.match(r'[a-z0-9]{8}-([a-z0-9]{4}-){3}[a-z0-9]{12}\.c4gh', row[0], re.ASCII)
    # checksum.  Rather than enforcing a specific length, which would enforce a specific checksum
    # algorithm, we check that this is the right format and at least 32 characters long.
    assert re.match(r'[a-z0-9]{32,}', row[2], re.ASCII)
    

def test_s3_to_s3(run_dir: Path, config_template: Dict[str, Any], destination_local_path: Path) -> None:
    test_helpers.run_workflow(config_template, run_dir)
    
    # Validate the workflow output. We access the contents of the S3 bucket
    # by directly accessing the underlying file system subdirectory

    local_index_path = destination_local_path / 'index.tsv'
    index = _read_index(local_index_path)
    assert len(index) > 0
    for row in index:
        _validate_index_row(row)
        received_file = destination_local_path / Path(row[1]).stem
        _validate_received_file(received_file)

    

def test_s3_to_local(run_dir: Path, config_template: Dict[str, Any], destination_local_path: Path) -> None:
    cfg = config_template
    cfg['destination'] = {
        'type': 'local',
        'root_path': str(destination_local_path)
    }
    test_helpers.run_workflow(cfg, run_dir)

    local_index_path = destination_local_path / 'index.tsv'
    index = _read_index(local_index_path)
    assert len(index) > 0
    for row in index:
        _validate_index_row(row)
        received_file = destination_local_path / Path(row[1]).stem  # take the .stem to remove the .c4gh extension
        _validate_received_file(received_file)


# File names in test repository:
#   test-file.txt
#   test-file_1.txt
#   test-file_2.txt
#   test-file_3.txt
#
# Remember that the filters are applied on the "final" file names (after decryption),
# and not on the file names in the index (which instead is the name of the encrypted file).
# The only difference between the two should be a .c4gh extension.

def test_just_include_filter(run_dir: Path, config_template: Dict[str, Any], destination_local_path: Path) -> None:
    cfg = config_template
    cfg['filters'] = [
        {'type': 'include',
         'pattern': 'test-file.*'}
    ]
    test_helpers.run_workflow(cfg, run_dir)

    local_index_path = destination_local_path / 'index.tsv'
    index = _read_index(local_index_path)
    assert len(index) == 4
    received_filenames = set(fpath.name for fpath in destination_local_path.iterdir() if fpath.name != 'index.tsv')
    assert {'test-file.txt', 'test-file_1.txt', 'test-file_2.txt', 'test-file_3.txt'} == received_filenames


def test_just_exclude_filter(run_dir: Path, config_template: Dict[str, Any], destination_local_path: Path) -> None:
    cfg = config_template
    cfg['filters'] = [
        {'type': 'exclude',
         'pattern': 'test-file.*'}
    ]
    test_helpers.run_workflow(cfg, run_dir)

    local_index_path = destination_local_path / 'index.tsv'
    index = _read_index(local_index_path)
    assert len(index) == 4

    received_filenames = set(fpath.name for fpath in destination_local_path.iterdir() if fpath.name != 'index.tsv')
    assert {'test-file_1.txt', 'test-file_2.txt', 'test-file_3.txt'} == received_filenames


def test_in_ex_filters(run_dir: Path, config_template: Dict[str, Any], destination_local_path: Path) -> None:
    cfg = config_template
    cfg['filters'] = [
        {'type': 'include',
         'pattern': 'test-file_2.txt'},
        {'type': 'exclude',
         'pattern': 'test-file_*'}
    ]
    test_helpers.run_workflow(cfg, run_dir)

    local_index_path = destination_local_path / 'index.tsv'
    index = _read_index(local_index_path)
    assert len(index) == 4

    received_filenames = set(fpath.name for fpath in destination_local_path.iterdir() if fpath.name != 'index.tsv')
    assert {'test-file.txt', 'test-file_2.txt'} == received_filenames


def test_ex_in_filters(run_dir: Path, config_template: Dict[str, Any], destination_local_path: Path) -> None:
    cfg = config_template
    cfg['filters'] = [
        {'type': 'exclude',
         'pattern': '*'},
        {'type': 'include',
         'pattern': 'test-file_2.txt'},
    ]
    test_helpers.run_workflow(cfg, run_dir)

    local_index_path = destination_local_path / 'index.tsv'
    index = _read_index(local_index_path)
    assert len(index) == 4

    received_filenames = set(fpath.name for fpath in destination_local_path.iterdir() if fpath.name != 'index.tsv')
    assert set() == received_filenames


def test_select_one_file_filter(run_dir: Path, config_template: Dict[str, Any], destination_local_path: Path) -> None:
    cfg = config_template
    cfg['filters'] = [
        {'type': 'include',
         'pattern': 'test-file_2.txt'},
        {'type': 'exclude',
         'pattern': '*'},
    ]
    test_helpers.run_workflow(cfg, run_dir)

    local_index_path = destination_local_path / 'index.tsv'
    index = _read_index(local_index_path)
    assert len(index) == 4

    received_filenames = set(fpath.name for fpath in destination_local_path.iterdir() if fpath.name != 'index.tsv')
    assert {'test-file_2.txt'} == received_filenames
